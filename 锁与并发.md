#### 并发线程

> 线程采用并发进行来提高执行效率与速度

```python
import socket
import threading #线程所需要的模块

#这个线程是用来发送数据
def send_msg(up_socket,dest_ip,dest_ports):
    while 1:
        dats = input("input the datas:")
        if dats == "break":
            break
        else:
            up_socket.sendto(dats.encode("utf-8"),(dest_ip,dest_ports))
   
#这个函数是用来接受数据
def recv_msg(up_socket):
    while 1:
        recv_data = up_socket.recvfrom(1024)
        if str(recv_data)=="break":
            break
        else:
            print(recv_data.decode("utf-8"))

def main():
  	#创建套接字
    up_socket=socket.socket(socket.AF_INET,socket.SOCK_DGRAM)
    #绑定端口和IP
    up_socket.bind(("",8080))

    dest_ip = input("input the ip:")
    dest_ports  = int(input("input the port:"))
    
    data = input("please input datas:")

    #设置线程target传的内容是需要调用的函数，args传的是函数需要调用的参数
    1. 调用recv_msg函数,参数为up_socket
    t_recv = threading.Thread(target=recv_msg,args=(up_socket,))
    2. 调用send_msg函数,参数为up_socket,dest_ip,dest_ports
    t_send = threading.Thread(target=send_msg,args=(up_socket,dest_ip,dest_ports,))
    #进程开始
    t_recv.start()
    t_send.start()

if __name__=="__main__":
    main()

```

#### 锁

> 定义锁的概念主要是为了防止在并发线程对全局变量的竞争使用而造成的混乱

```python
import socket
import time 
import threading

#全局变量
g_num = 0


def test1(num):
    global g_num
    for i in range(num):
        mutex.acquire() #在这里进行上锁,进程使用全局变量是需要锁
        g_num+=1
        mutex.release() #对变量修改完成，可释放锁
    print("-------test1---------%d"%g_num)

def test2(num):
    global g_num
    for i in range(num):
        mutex.acquire()
        g_num+=1
        mutex.release()
    print("-------test2---------%d"%g_num)

mutex = threading.Lock() #定义锁

def main():
    print("start")
    t1 = threading.Thread(target=test1,args=(10000000,))
    t2 = threading.Thread(target=test2,args=(10000000,))
    t1.start()
    t2.start()

    time.sleep(2)
    print("--------main---------%d"%g_num)

if __name__ =="__main__":
    main()

```

#### 进程

> import multiprocessing  #进程所需要的模块
>
> t2 = multiprocessing.Process(target=test2) #进程与线程类似使用的的是Process函数
>
> t2.start() #进程运行

```python
import threading
import time
import multiprocessing  #进程所需要的模块

def test1():
    count = 0
    while 1:
        count+=1
        if count ==3:
            break
        print("test1----------------")
        time.sleep(1)

def test2():
    while 1:
        print("test2----------------")
        time.sleep(1)

def main():
  	#进程与线程类似使用的的是Process函数
    t1 = multiprocessing.Process(target=test1)
    t2 = multiprocessing.Process(target=test2)
    t1.start()
    t2.start()

if __name__=="__main__":
    main()

```

#### 进程池

* 进程池是采用开启几个进程让这几个进程一起去执行程序,没有处理的程序就阻塞等待进程池里的进程空闲
* 如在进程池开5个进程去处理100个程序,刚开始处理5个其他95个等待直到着5个进程有空闲时处理其他程序

> from multiprocessing import Pool #进程池所需要的模块
>
>  po = Pool(3) #开启3个进程
>
>  po.apply_async(test,(i,)) #将程序(函数)加如到进程池，后面的i是参数
>
> po.close() #关闭进程池,使po不再接受新的请求
>
> po.join() #让主进程等待po中所有的子进程执行完成，必须放在close()语句后

```python
from multiprocessing import Pool #进程池所需要的模块
import time,os,random

def test(msg):
    t_start = time.time()
    #os.getpid()获取该进程的ID
    print("%s开始执行，进程号为%d"%(msg,os.getpid()))
    time.sleep(random.random()*2)
    t_stop = time.time()
    print(msg,"执行完毕，耗时%0.2f"%(t_stop-t_start))

def main(po):
    for i in range(0,10):
      	#将程序(函数)加如到进程池，后面的i是参数
        po.apply_async(test,(i,))

if __name__=="__main__":
  	#开启3个进程
    po = Pool(3)
    main(po)
    print("------start-----")
    #关闭进程池,使po不再接受新的请求
    po.close()
		#让主进程等待po中所有的子进程执行完成，必须放在close()语句后
    po.join()
    print("------end-------")

```

#### 进程间拷贝目录文件

```python
import multiprocessing
import os,time

def copy(old_filename,new_filename,file_name):
    print("从%s拷贝文件到%s,文件名%s"%(old_filename,new_filename,file_name))
    #以读的形式打开目录里面的文件
    old_f = open(old_filename+"/"+file_name,"rb")
    #读取里面的数据
    content = old_f.read()
    old_f.close()
		
    #在新目录里打开文件(创建)
    new_f = open(new_filename+"/"+file_name,"wb")
    #把读取到的数据写入其中
    new_f.write(content)
    new_f.close()

def main():
    old_filename = input("请输入要copy的文件:")
    #捕捉错误
    try:
      	#生成的新目录名字
        new_filename = old_filename+"[复件]"
        # os.mkdir()函数生成一个目录文件
        os.mkdir(new_filename)
    except:
        pass
    #os.listdir(目录)取出目录中所有的文件名，以元组的形式
    file_names = os.listdir(old_filename)
    #开5个进程
    pool = multiprocessing.Pool(5)
    #对目录中的所有文件进行循环
    for file_name in file_names:
      	#对文件进行拷贝,采用进程池的方式
        pool.apply_async(copy,args=(old_filename,new_filename,file_name))
    print("--------start-------------")
    pool.close()
    #阻塞等待
    pool.join()
    print("----------end-------------")


if __name__ =="__main__":
    main()

```

#### 队列通信

```python
import multiprocessing
import time

def test1(q):
    data = [1,2,3,4,5,6]
    for i in data:
      	#向队列中写入数据
        q.put(i)
       # print(i)
    print("数据已经存到队列中....")

def test2(q):
    waiting_data = list()
    while True:
            if q.empty():
                break
            else:
              	#读取队列中的数据
                p = q.get()
                waiting_data.append(p)
    print(waiting_data)
    print("完成......")

def main():
    #创建队列
    q = multiprocessing.Queue()
    t1 = multiprocessing.Process(target=test1,args=(q,))
    t2 = multiprocessing.Process(target=test2,args=(q,))
    t1.start()
    time.sleep(1)
    t2.start()

if __name__=="__main__":
    main()

```

